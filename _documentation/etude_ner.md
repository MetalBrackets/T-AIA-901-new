# Restitution de l'√©tude

## Choix de 3 mod√®les

Pour rester uniforme par ex dans la mise en commun des fonctions ou dans l'affichage et la comparaison des sorties,
on va utiliser des mod√®les qui ont la m√™me strat√©gie de segmentation.
On exclue ici FlauBERT et CamemBERT car dans leur m√©thode de tokenisation, la syntaxe diff√®re.
üî¨ Voir le resultat de l'√©tude [de la tokenisation](../model/SANDRINE/sandbox/Etude-tokenization.md)

## Finetuning des mod√®les

- [bert-base-multilingual-cased](../model/SANDRINE/finetuning-bert-base-fr-cased.ipynb)
- [bert-base-fr-cased](../model/SANDRINE/finetuning-bert-base-multilingual-cased.ipynb)
- [NER_MobileBert](../model/SANDRINE/finetuning-NER_MobileBert.ipynb)

## Comparaison des entrainements

| bert-base-multilingual-cased                                                         | bert-base-fr-cased                                                | NER_MobileBert                                                        |
| :----------------------------------------------------------------------------------- | :---------------------------------------------------------------- | :-------------------------------------------------------------------- |
| google                                                                               | Geotrend                                                          | SKNahin                                                               |
| Downloads last month 8780                                                            | Downloads last month 131                                          | Downloads last month 10                                               |
| Poids : 1.08 GB                                                                      | Poids : 499 MB                                                    | Poids : 98.5 MB                                                       |
| ![Matrix multilingual](./ai-screens/matrix_bertbase-multilingue.png)                 | ![Matrix fr](./ai-screens/matrix_bertbase-fr.png)                 | ![Matrix NER](./ai-screens/matrix_mobilebert.png)                     |
| ![Classification multilingual](./ai-screens/classification_bertbase-multilingue.png) | ![Classification fr](./ai-screens/classification_bertbase-fr.png) | ![Classification NER](./ai-screens/classification_ner-mobilebert.png) |
| ![Text1 multilingual](./ai-screens/base-multilingual-cased-epoch.png)                | ![Text1 fr](./ai-screens/base-fr-cased-epoch.png)                 | ![NER text1](./ai-screens/ner-mobilebert-epoch.png)                   |
| ![ROC multilingual](./ai-screens/roc_bertbase-multilingue.png)                       | ![ROC fr](./ai-screens/roc_bertbase-fr.png)                       | ![ROC NER](./ai-screens/roc_ner-mobilebert.png)                       |

## XAI

Explicabilit√© et interpretabilit√©  
[bert-base-multilingual-cased](../back/test/test-xai.ipynb)

On peut voir l'√©volution de la r√©partition des poids √† travers les 5 derni√®res couches

Output Tokens - le token que le mod√®le est en train d'analyser  
Input Tokens - l'ensemble des tokens disponibles en entr√©e sur lesquels le mod√®le peut "porter son attention"

- Les tokens regardent plusieurs autres tokens pour contextualiser leur sens
- Certains tokens se focalisent davantage sur un petit nombre de tokens
- Le mod√®le affine progressivement la repr√©sentation des mots, des liaisons, du sens
- L'embeding se stabilise avec des mots "autofocus√©" pour la t√¢che de classification

| bert-base-multilingual-cased                                            | bert-base-fr-cased                                  | NER_MobileBert                                        |
| :---------------------------------------------------------------------- | :-------------------------------------------------- | :---------------------------------------------------- |
| ![Text1 multilingual](./ai-screens/base-multilingual-cased-text1.png)   | ![Text1 fr](./ai-screens/base-fr-cased-text1.png)   | ![NER text1](./ai-screens/ner-mobilebert-text1.png)   |
| ![Tokens multilingual](./ai-screens/base-multilingual-cased-tokens.png) | ![Tokens fr](./ai-screens/base-fr-cased-tokens.png) | ![NER tokens](./ai-screens/ner-mobilebert-tokens.png) |
| _Autres informations multilingues ici_                                  | _Autres informations en fran√ßais ici_               | _Autres informations sur NER ici_                     |
| Ligne 9                                                                 | Ligne 9                                             | Ligne 9                                               |
| Ligne 10                                                                | Ligne 10                                            | Ligne 10                                              |

### Conclusion

Les mod√®les bert-base-fr-cased et bert-base-multilingual-cased identifient correctement les entit√©s de destination (DEP et ARR) dans les deux phrases sur des phrases simples.  
En revanche, le mod√®le NER_MobileBert montre des erreurs sur la deuxi√®me phrase, √©chouant √† d√©tecter correctement "Paris", "Albert" et "Monaco".  
Ces r√©sultats sugg√®rent que Les BERT sont plus performant que le MobileBERT.

## Choix du mod√®le final

üéâüéâüéâ Bert base fr
Il est plus rapide et d√©j√† pr√©-entrain√© sur le fran√ßais.
