{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T10:40:58.562928Z",
     "start_time": "2024-12-13T10:40:58.540934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import CamembertTokenizer, CamembertForTokenClassification\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "df = pd.read_csv('../../data/reservation-first-dataset-train.csv')\n",
    "#dataset = load_dataset('csv', data_files={'train': '../../data/reservation-first-dataset-train.csv', 'test': '../../data/reservation-first-dataset-test.csv'})\n",
    "print(df.head())"
   ],
   "id": "f7284aa3c637f1d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Phrase                 Départ  \\\n",
      "0  montre-moi les trains dimanche allant de Jarvi...  Jarville-la-Malgrange   \n",
      "1  quels trains voyagent d'Alençon à Corbeil-Esso...                Alençon   \n",
      "2  montre-moi les trains pour Saint-Avold depuis ...               Xertigny   \n",
      "3  montrer les trains de Gargan à Valdahon Camp M...                 Gargan   \n",
      "4  quels trains sont disponibles de Montbard à Sa...               Montbard   \n",
      "\n",
      "                   Arrivée  \n",
      "0      La Bassée-Violaines  \n",
      "1         Corbeil-Essonnes  \n",
      "2              Saint-Avold  \n",
      "3  Valdahon Camp Militaire  \n",
      "4      Saint-Romain-le-Puy  \n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Préparation des labels pour la classification",
   "id": "250cbae259ea582e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T10:38:24.495781Z",
     "start_time": "2024-12-13T10:38:24.487545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def prepare_labels(sentence, departure, arrival):\n",
    "    # Tokenisation de la phrase en sous-tokens\n",
    "    token_strs = sentence.split()\n",
    "\n",
    "    print(token_strs)\n",
    "    labels = []\n",
    "    is_departure = False\n",
    "    is_arrival = False\n",
    "    # Parcourir chaque token\n",
    "    for i, token in enumerate(token_strs):\n",
    "        print(\"Token: \", token)\n",
    "    # Vérifier si le token contient une partie de la ville de départ\n",
    "    if departure in token:\n",
    "        if not is_departure:\n",
    "            labels.append('B-START')  # Premier token de départ\n",
    "            is_departure = True\n",
    "        else:\n",
    "            labels.append('I-START')  # Sous-token suivant du départ\n",
    "            # Vérifier si le token contient une partie de la ville d'arrivée\n",
    "    elif arrival in token:\n",
    "        if not is_arrival:\n",
    "            labels.append('B-END')  # Premier token de l'arrivée\n",
    "            is_arrival = True\n",
    "        else:\n",
    "            labels.append('I-END')  # Sous-token suivant de l'arrivée\n",
    "    else:\n",
    "        labels.append('O')  # Pas d'entité\n",
    "        print(\"Non encodés: \", labels)\n",
    "        \n",
    "        # Encoder les labels textuels en valeurs numériques\n",
    "        label_encoder = LabelEncoder()\n",
    "        encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "    return encoded_labels   \n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "65d1bbb051f2d034",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T10:39:41.023797Z",
     "start_time": "2024-12-13T10:39:30.671268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tokenisation et préparation des labels\n",
    "tokenizer = CamembertTokenizer.from_pretrained('camembert-base', do_lower_case=True)\n",
    "train_data = []\n",
    "\n",
    "# Boucle sur les lignes du DataFrame\n",
    "for i, row in df.iterrows():\n",
    "    if i < 5:  # Limiter à 5 lignes pour le test\n",
    "        sentence = row['Phrase']\n",
    "        departure = row['Départ']\n",
    "        arrival = row['Arrivée']\n",
    "    \n",
    "        print(\"La phrase: \", sentence)\n",
    "        # Tokeniser la phrase\n",
    "        tokenized_sentence = tokenizer(sentence , truncation=True, padding='max_length', max_length=36)\n",
    "        tokens = tokenized_sentence['input_ids']\n",
    "        \n",
    "        # Préparer les labels\n",
    "        labels = prepare_labels(sentence, departure, arrival)\n",
    "    \n",
    "        # Afficher les tokens et les labels\n",
    "        print(\"Tokens: \", tokenizer.convert_ids_to_tokens(tokens))  # Afficher les tokens\n",
    "        print(\"Labels (encoded): \", labels)  # Afficher les labels encodés\n",
    "    \n",
    "        # Ajouter les données au jeu d'entraînement\n",
    "        train_data.append({\n",
    "            \"input_ids\": tokenized_sentence[\"input_ids\"],\n",
    "            \"attention_mask\": tokenized_sentence[\"attention_mask\"],\n",
    "            \"labels\": labels\n",
    "        })\n",
    "        \n",
    "\n",
    "# Conversion en Dataset\n",
    "train_dataset = Dataset.from_pandas(pd.DataFrame(train_data))\n",
    "\n"
   ],
   "id": "e713719387464a50",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La phrase:  montre-moi les trains dimanche allant de Jarville-la-Malgrange à La Bassée-Violaines en première classe sans correspondance partant l'après midi\n",
      "['montre-moi', 'les', 'trains', 'dimanche', 'allant', 'de', 'Jarville-la-Malgrange', 'à', 'La', 'Bassée-Violaines', 'en', 'première', 'classe', 'sans', 'correspondance', 'partant', \"l'après\", 'midi']\n",
      "Token:  montre-moi\n",
      "Token:  les\n",
      "Token:  trains\n",
      "Token:  dimanche\n",
      "Token:  allant\n",
      "Token:  de\n",
      "Token:  Jarville-la-Malgrange\n",
      "Token:  à\n",
      "Token:  La\n",
      "Token:  Bassée-Violaines\n",
      "Token:  en\n",
      "Token:  première\n",
      "Token:  classe\n",
      "Token:  sans\n",
      "Token:  correspondance\n",
      "Token:  partant\n",
      "Token:  l'après\n",
      "Token:  midi\n",
      "Non encodés:  ['O']\n",
      "Tokens:  ['<s>', '▁montre', '-', 'moi', '▁les', '▁trains', '▁dimanche', '▁allant', '▁de', '▁Jar', 'ville', '-', 'la', '-', 'Mal', 'g', 'range', '▁à', '▁La', '▁Bas', 'sée', '-', 'Vi', 'ola', 'ines', '▁en', '▁première', '▁classe', '▁sans', '▁correspondance', '▁partant', '▁l', \"'\", 'après', '▁midi', '</s>']\n",
      "Labels (encoded):  [0]\n",
      "La phrase:  quels trains voyagent d'Alençon à Corbeil-Essonnes\n",
      "['quels', 'trains', 'voyagent', \"d'Alençon\", 'à', 'Corbeil-Essonnes']\n",
      "Token:  quels\n",
      "Token:  trains\n",
      "Token:  voyagent\n",
      "Token:  d'Alençon\n",
      "Token:  à\n",
      "Token:  Corbeil-Essonnes\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'encoded_labels' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnboundLocalError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[60], line 18\u001B[0m\n\u001B[1;32m     15\u001B[0m tokens \u001B[38;5;241m=\u001B[39m tokenized_sentence[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# Préparer les labels\u001B[39;00m\n\u001B[0;32m---> 18\u001B[0m labels \u001B[38;5;241m=\u001B[39m \u001B[43mprepare_labels\u001B[49m\u001B[43m(\u001B[49m\u001B[43msentence\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdeparture\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marrival\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# Afficher les tokens et les labels\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTokens: \u001B[39m\u001B[38;5;124m\"\u001B[39m, tokenizer\u001B[38;5;241m.\u001B[39mconvert_ids_to_tokens(tokens))  \u001B[38;5;66;03m# Afficher les tokens\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[59], line 34\u001B[0m, in \u001B[0;36mprepare_labels\u001B[0;34m(sentence, departure, arrival)\u001B[0m\n\u001B[1;32m     31\u001B[0m     label_encoder \u001B[38;5;241m=\u001B[39m LabelEncoder()\n\u001B[1;32m     32\u001B[0m     encoded_labels \u001B[38;5;241m=\u001B[39m label_encoder\u001B[38;5;241m.\u001B[39mfit_transform(labels)\n\u001B[0;32m---> 34\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mencoded_labels\u001B[49m\n",
      "\u001B[0;31mUnboundLocalError\u001B[0m: cannot access local variable 'encoded_labels' where it is not associated with a value"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8c26cde6fc39e9c2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
